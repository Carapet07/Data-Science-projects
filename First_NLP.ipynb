{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOY3z9oip0sLdiOL5bfpplt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carapet07/Data-Science-projects/blob/main/First_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##My first NLP project"
      ],
      "metadata": {
        "id": "B7qqSjS52gJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib, shutil, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "kj4RY4Norqpb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFU6Gvlrrm0Z",
        "outputId": "416bdcc7-aeb3-438f-d803-c023d1edec62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  3156k      0  0:00:26  0:00:26 --:--:-- 4390k\n",
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup\n",
        "!cat aclImdb/train/pos/4077_10.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "  os.makedirs(val_dir / category)\n",
        "  files = os.listdir(train_dir / category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int(0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category / fname,\n",
        "                val_dir / category / fname)"
      ],
      "metadata": {
        "id": "jcjZF4pMsS8i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "HykwDKwxvtqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13cca8e-c34f-4605-c9dd-740a7a13cef7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):  # Take one batch\n",
        "    for i in range(5):  # Show first 5 examples\n",
        "        print(f\"Text: {text_batch.numpy()[i].decode('utf-8')}\")\n",
        "        print(f\"Label: {label_batch.numpy()[i]}\")\n",
        "        print(\"=\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n4BzlrG1S-8",
        "outputId": "4ad59b44-3d03-4cb8-dd42-8528c56c565a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I was babysitting a family of three small children for a night and their mother gave me this to show for them having just grabbed it at Wal-Mart earlier in the week. All three children actually got physically ill while watching it. I'm pretty sure it was the pizza they ate, or something they all had picked up from school, but really it could have been this film. Absolutely disgusting. How any one can produce this caliber of trash is beyond me. Fortunately, I turned off the film when I noticed the children were not responding and acting strangely. For any parents out there, I strongly advise you to refrain from letting young children view this movie.\n",
            "Label: 0\n",
            "==================================================\n",
            "Text: We do not come across movies on brother-sister relationship in Indian cinema, or any other language or medium. This relationship has several aspects which have not been exploited in movies or novels. Typically, a sister is depicted as a pile-on who can be used for ransom in the climax. This movie treats the subject in an entirely different light.<br /><br />It is inspired by George Eliot's novel \"The Mill on the Floss\". The brother is very prosaic, all-good, the blue-eyed boy who is a conventionally good son and a favorite with his mother. The sister is romantic, wild and defiant of the unwritten rules of the society. In spite of this, the love of the brother-sister is the winner.<br /><br />This movie is about the love of the two siblings who are separated in childhood and revival of the same feeling when they meet years later. It is also the quest of the subdued brother to reunite with his sister who has chosen to be wild to defy the world.<br /><br />Although the movie and the novel are set about 3 centuries apart in two distant countries, yet the sentiments are the same and still hold true.\n",
            "Label: 1\n",
            "==================================================\n",
            "Text: This is going to be the most useless comment I have ever put down, but yet I must do it to warn you about the atrocity to cinema that \"Freddy's Dead\" is. It is not only the very worst chapter of the Nightmare series, but is right up there with the worst horror sequel of all time! It was boring, pointless, and nearly death free. The horrible 3-D ending and over-the-top CORNY kills are enough to drive this \"film\" into the ground. However, it doesn't stop there, just add bad acting, a terrible script, and a number of cheesy cameos and you've got yourself this heaping pile of guano! It's no wonder why Freddy, as always played by Robert Englund, has made two postmortem appearances. I would too if I went out like that. This is a strictly fans only movie, don't stare at our shame.\n",
            "Label: 0\n",
            "==================================================\n",
            "Text: Obviously a film that has had great influence not only on the buddy genre but action genre as well. George Lucas had to be a fan of this flick as so much of his Star Wars series seems to a homage to Gunga Din. The characters that Grant, McLaglen, and Fairbanks play are just precursors of Han Solo, Luke Skywalker, and Chewbacca. Even Sam Jaffe's Gunga Din morphed into C-3PO and R2-D2 and like him or not: Jar Jar Binks.<br /><br />Today this film is viewed as non PC but there is a speech by Eduardo Ciannelli as Guru the leader of the Indian opposition to the British raj that could can be echoed in the sentiments of many today. <br /><br />To a young boy this was a great film. Three strong male leads and only a hint of romance. There was a time when young boys deemed kissing the girl in Saturday matinee film was just mush. Not like today when the more skin is greeted with delight. Too late to lament lost innocence.<br /><br />Hopefully this film will not be forgotten and a few who are channel surfing will stop at TCM and catch a film with action, adventure, and a cast of thousands instead of CGI actors.\n",
            "Label: 1\n",
            "==================================================\n",
            "Text: Alien Hunter: 5 out of 10: Is it me or does every movie that starts in Roswell, New Mexico suck. Take Alien mixed with The Thing, mixed with Contact, mixed with of all things On the Beach, The Andromeda Strain, the classroom scene from Raiders of the Lost Ark and a throw in a little Stargate to boot. <br /><br />Derivative doesn't even begin to describe this movie. Of course with nothing original plot wise they amp up the gore and sex right? Nope gore is a blink and you miss it affair and sex is all tease. (James Spader causally mentions he needs a shower and the delectable Leslie Stefanson asks to join him. he turns her down. AGGH!) <br /><br />In fact if a movie ever needed a shower scene to liven things up this is it. I mean if your going to have impossibly good-looking women in white bathing suits wandering around an Antarctica research base why not go for broke.<br /><br />With about 30 seconds of actual thrill in the entire movie Alien Hunter is remarkable serious and slow going for a sci-fi adventure. Needed a much better plot twist to liven it up and by the way the Alien itself is a horribly clichéd artifice and has virtually no screen time for someone who shares half the title. <br /><br />I also inquired during viewing what is with the Children of the Corn in space motif. (Note that since Jason of Friday the 13th fame, Pinhead from Hellraiser and that Leprechaun have all traveled to space to slay nubile teenagers why not the cornfield?) The characters in the cornfield dress like Logan's Run extras and I was just waiting for the stalks to come alive and attack them.<br /><br />That however would have been exciting and apparently against this movies covenant. The acting is mostly fine as Spader reprises his Stargate role while Stefanson and Janine Eser model the latest in Antarctic beachwear. John Lynch however read the whole script and acts the like the insane bad guy well before the story would indicate it.<br /><br />Alien Hunter is a disappointing derivative slog that makes me pine for a proper Children of The Corn in Space movie.\n",
            "Label: 0\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_length\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y),\n",
        "                            num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y),\n",
        "                            num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y),\n",
        "                            num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "Fbs7ryTqs5j-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "  print(\"input shape: \", inputs.shape)\n",
        "  print(\"input dtype: \", inputs.dtype)\n",
        "  print(\"targets shape: \", targets.shape)\n",
        "  print(\"targets dtype: \", targets.dtype)\n",
        "  print('inputs[0]: ', inputs[0])\n",
        "  print('targets[0]: ', targets[0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEyeDCVK0-0p",
        "outputId": "75433afc-425c-4be6-a373-39cfdf5222b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape:  (32,)\n",
            "input dtype:  <dtype: 'string'>\n",
            "targets shape:  (32,)\n",
            "targets dtype:  <dtype: 'int32'>\n",
            "inputs[0]:  tf.Tensor(b'Thunderbirds (2004) <br /><br />Director: Jonathan Frakes <br /><br />Starring: Bill Paxton, Ben Kingsley, Brady Corbet <br /><br />5\\xc2\\x854\\xc2\\x853\\xc2\\x852\\xc2\\x851! Thunderbirds are GO! <br /><br />And so began Thunderbirds, a childhood favorite of mine. When I heard that they were going to make a Thunderbirds movie, I was ecstatic. I couldn\\'t wait to see Thunderbird 2 roar in to save people, while Thunderbird 4 would dive deep into the\\xc2\\x85you get the idea. I just couldn\\'t wait. Then came August 2004, when the movie was finally released. Critics panned it, but I still wanted to go. After all, as long as the heart was in the same place, that was all that mattered to me. So I sat down in the theater, the only teenager in a crowd of 50\\xc2\\x85everyone else was over thirty and under ten. Quite possibly the most awkward theater experience that I have ever had\\xc2\\x85 <br /><br />The movie (which is intended to be a prequel) focuses on Alan Tracy (Brady Corbet), the youngest of the Tracy family. He spends his days wishing that he could be rescuing people like the rest of his family, but he\\'s too young. One day, he finally gets his chance when The Hood (Ben Kingsley) traps the rest of his family up on Thunderbird 5 (the space station). This involves him having to outsmart The Hood\\'s henchmen and rescue his family in time before The Hood can steal all of the money from the Bank of England.<br /><br />Trust me, the plot sounds like a regular episode of Thunderbirds when you read it on paper. Once it gets put on to film\\xc2\\x85what a mess we have on our hands. First off, the film was intended for children, much like the original show was. However, Gerry Anderson treated us like adults, and gave us plots that were fairly advanced for children\\'s programming. This on the other hand, dumbs down the plot as it tries to make itself a ripoff of the Spy Kids franchise. The final product is a movie that tries to appeal to fans of the Thunderbirds series and children, while missing both entirely. Lame jokes, cartoonish sounds, and stupid antics that no one really finds amusing are all over this movie, and I\\'m sure that Jonathan Frakes is wishing he\\'d never directed this.<br /><br />Over all, everyone gave a solid performance, considering the script that they were all given. Ben Kingsley was exceptional as The Hood, playing the part extremely well. My only complaint about the characters is about The Hood\\'s henchmen, who are reduced to leftovers from old Looney Tunes cartoons, bumbling about as, amazingly enough, the kids take them on with ease.<br /><br />What\\'s odd about this movie is that while I was watching the movie, I had fun. But once the lights went up, I realized that the movie was fairly bad, I was $8 lighter, and two hours of my time were now gone. A guilty pleasure? Perhaps. Nonetheless, Thunderbirds is a forgettable mess. Instead of a big \"go\", I\\'m going to have to recommend that you stay away from this movie. If the rest of movie could have been like the first ten minutes of it, it would have been an incredible film worthy of the Thunderbirds name. However, we get a movie that only die-hard Thunderbirds fans (if you\\'d like to watch your childhood torn to pieces) or the extremely bored should bother with.<br /><br />My rating for Thunderbirds is 1 \\xc2\\xbd stars.', shape=(), dtype=string)\n",
            "targets[0]:  tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset yields inputs that are tf.string tensors and targets that are int32 tensors encoding the value \"0\" or \"1\"\n",
        "\n",
        "\n",
        "All set, now let's try learnign something from this data\n"
      ],
      "metadata": {
        "id": "rkkTRznT2IO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(None, ), dtype='int64')\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=128, input_length=max_length)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6VVVXhop2EXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "aaedd107-0a62-45bb-f75c-36cdcd15ad6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m41,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,601,281\u001b[0m (9.92 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,601,281</span> (9.92 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,601,281\u001b[0m (9.92 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,601,281</span> (9.92 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                      save_best_only=True)\n",
        "    ]\n",
        "\n",
        "history = model.fit(int_train_ds.cache(),\n",
        "  validation_data=int_val_ds.cache(),\n",
        "  epochs=10,\n",
        "  callbacks=callbacks)\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJrWeNRPrubQ",
        "outputId": "fd5478a6-b8ad-4106-f7d9-9f6589724863"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 42ms/step - accuracy: 0.6363 - loss: 0.6242 - val_accuracy: 0.8386 - val_loss: 0.3952\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 39ms/step - accuracy: 0.8322 - loss: 0.4104 - val_accuracy: 0.8654 - val_loss: 0.3414\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.8788 - loss: 0.3251 - val_accuracy: 0.8784 - val_loss: 0.3154\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9069 - loss: 0.2717 - val_accuracy: 0.8658 - val_loss: 0.3262\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9158 - loss: 0.2407 - val_accuracy: 0.8794 - val_loss: 0.3339\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9275 - loss: 0.2160 - val_accuracy: 0.8872 - val_loss: 0.3065\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9352 - loss: 0.1868 - val_accuracy: 0.8064 - val_loss: 0.6082\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9471 - loss: 0.1626 - val_accuracy: 0.8788 - val_loss: 0.3597\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.9558 - loss: 0.1340 - val_accuracy: 0.8786 - val_loss: 0.3959\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.9652 - loss: 0.1146 - val_accuracy: 0.8744 - val_loss: 0.4252\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8755 - loss: 0.4160\n",
            "Test acc: 0.874\n"
          ]
        }
      ]
    }
  ]
}