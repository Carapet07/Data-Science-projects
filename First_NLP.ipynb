{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNaKxzfVr1/MDFbe6o22/Vr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carapet07/Data-Science-projects/blob/main/First_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##My first NLP project"
      ],
      "metadata": {
        "id": "B7qqSjS52gJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib, shutil, random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "kj4RY4Norqpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFU6Gvlrrm0Z",
        "outputId": "71daf4f3-f014-4a44-e91d-0e404a8f535d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  51.0M      0  0:00:01  0:00:01 --:--:-- 51.1M\n",
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup\n",
        "!cat aclImdb/train/pos/4077_10.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "  os.makedirs(val_dir / category)\n",
        "  files = os.listdir(train_dir / category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int(0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category / fname,\n",
        "                val_dir / category / fname)"
      ],
      "metadata": {
        "id": "jcjZF4pMsS8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "HykwDKwxvtqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78455112-4f95-40cf-97c7-f22c0d677276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):  # Take one batch\n",
        "    for i in range(5):  # Show first 5 examples\n",
        "        print(f\"Text: {text_batch.numpy()[i].decode('utf-8')}\")\n",
        "        print(f\"Label: {label_batch.numpy()[i]}\")\n",
        "        print(\"=\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n4BzlrG1S-8",
        "outputId": "2f302d18-0c27-46a2-c17d-76a83628f1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: After having red the overwhelming reviews this film got in my country, I but wanted to see it. But - what a disappointment! To see a bunch of one-dimensional characters in a plot that lacks of originality is not worth the money and the time to spend. I sometimes wonder about the filmcritics in switzerland.\n",
            "Label: 0\n",
            "==================================================\n",
            "Text: Bo Derek might have had a career had she not let her late husband, John, take over as her director. It's a real shame, no really, with the right direction and the right part (see \"10\"), Bo was okay. She wouldn't win any awards even at her best, but she is no worse than many an actress who has made it big in the past 15 years or so based on looks alone. But therein lay the problem, John was determined to ride the wave that Bo created with her appearance in 10, that of Bo being the \"perfect 10,\" \"the hottest woman in America,\" \"the sex symbol of the 1980s.\" Problem is, in John's hands, this wave crashed with a resounding thud in only a few year's time. Maybe he knew her limitations as an actress, perhaps that is why he fashioned movies for her that concentrated on her body, not her acting skills. But it got old real quick. It didn't help matters any that the films of John and Bo Derek are (let's be honest) really, really bad. And bad sums up their take on Edgar Rice Burrough's literary icon, the Lord of the Jungle, Tarzan of the Apes.<br /><br />You know what's worst? This film is boring! Make me laugh, make me cry, just don't bore me. Not even Bo's stunning looks and figure can rouse any interest, and that is what the film is of course built around. Richard Harris (God bless his soul, he and Bo were previously in Orca btw) hams it up and makes his scenes at least a little interesting and Miles O'Keefe makes a physically impressive Tarzan. Maybe he got the last laugh, after being hit with a ton of venom from the critics over this film, Miles went on to a solid career as a B movie icon, in films that were not great art, but a million times more fun than this one. But other than that, it's Bo's body,and you can only see it so many times before you long for something else to go with it. Tarzan the Ape Man has nothing else. John Derek was a truly dynamic actor, he was not a director. He should have stayed with his strength. This film unfolds at a mind numbingly slow pace and nothing really happens in the action scenes. Burrough's Tarzan was all about excitement and wish fulfillment (who wouldn't want to be as agile, strong and good looking as Lord Greystoke?) and fun! You get none of that here. Watch it, and you will have wasted 107 minutes of your life. On second thought, you may come away with a valuable lesson, how not to handle someone's movie career. <br /><br />Bo Derek is all right in my book though. She stood by John until his dying day, has a true love of animals and nature and even looks back with a giggle at her time in the spotlight. She has also proven that she is not the dumb blonde many want her to make her out to be. If she could survive Tarzan and Bolero, she can survive anything. So come back Bo, all is forgiven.<br /><br />And as an aside, is the Steve Strong who plays the bad guy the same Steve Strong who a brief pro wrestling career?\n",
            "Label: 0\n",
            "==================================================\n",
            "Text: Nothing to say but Wow! Has anyone actually had somebody sneak up on them in an open field? Well this happens about 25 times in this movie(clearly the directors' favorite scare tactic). In one of the opening scenes the smooth talking/hot shot producer has to ride in the back seat so the camera man could sit in the front to film. Shortly after he arrives to the field the 5 contestants show up and, although it is clearly at latest 2 in the afternoon they are all convinced that the sun will set any minute. After about 30 minutes of boobless trash we are privileged with a flashback of the clown's history in which we see some of his previous victims. If you watch this movie check out the ladies chest.. her ribs go all the way to her neck, it was flat out disgusting. Most horror movies action occurs during the night but without a night vision camera the chaos is forced to happen during the day. The few night shots that did make it in to the movie look like they were stolen from the Blair Witch Project or random shots from the directors backyard. The movie somewhat redeemed itself in the end when there was a matrix like shoot out with the clown that we rewound and watched over and over laughing hysterically.<br /><br />Definitely RENT THIS MOVIE IF YOU HAVE EVER BEEN SNUCK UP ON IN AN OPEN FIELD.<br /><br />SIGNED, THE ANSWER\n",
            "Label: 0\n",
            "==================================================\n",
            "Text: This has to be one the best movies about serial killers that I've ever seen, and this is coming from someone who absolutely loved Silence of the Lambs. HBO has hit the jackpot here. This film is compelling from the first moment until the last.<br /><br />This film has so many underlying themes its hard to tell exactly what it is about. It chronicles the decade-long search for the Russian serial killer Andrea Chikatilo. Stephen Rea gives a brilliantly reserved performance as the inexperienced forensic expert who is put in charge of the investigation, and Donald Sutherland gives an even more involving performance as his cynical superior, and the only person in the Russian government willing to help him. Both of their performances are subtle masterpieces---Rea begins naive and unwilling to compromise, while Sutherland begins detached and almost amused by the situation. Towards the end, Rea becomes more world-weary and beaten by the system, while Sutherland finds himself more passionate and idealistic.<br /><br />In any other movie, I would have said that Sutherland's performance stands out above the rest, but here even it is rivaled by Jeffrey DuMann, as the serial killer himself. DuMann brilliantly creates a character here who inspires empathy rather than the hatred we think we would find---he is a monster, but he doesn't want to be, and we get the idea that he is just as disgusted with what he does as we are. He is tortured, ashamed, but vicious as well.<br /><br />If you can take the incredibly dark subject matter, (and it is *very* disturbing), then you should see this movie.\n",
            "Label: 1\n",
            "==================================================\n",
            "Text: I remember the first time I saw this movie -- I was in the office working over the weekend & the TV was on for background noise. But I gradually found myself more & more engaged in this movie I'd never seen or heard of, until I was completely absorbed. A Matter of Life & Death (the British title -- Stairway to Heaven in the US) is delightful, compelling, whimsical, & moving, all in one superbly-written, well-acted, perfectly-directed package. It's a classic that really does rank right up there with Casablanca, It's a Wonderful Life, Gone With the Wind, Citizen Kane, & Chariots of Fire. WHY has it never received the same public notice & video-store prominence? Fortunately, SOME knowledgeable critics HAVE put it on their \"Top 100 of all time\" lists. There IS hope -- 1940's Fantasia wasn't a hit 'til the '60s, & the Wizard of Oz was a dud at the box office, but made a hit by TV. Buy it -- rent it -- watch it -- demand it! You WON'T be disappointed!\n",
            "Label: 1\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_length\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y),\n",
        "                            num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y),\n",
        "                            num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y),\n",
        "                            num_parallel_calls=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "Fbs7ryTqs5j-",
        "outputId": "b0c9db7d-4978-4afb-a98b-d11b8a616186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-15-afd9aa746c28>, line 12)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-afd9aa746c28>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    num_parallel_calls=4)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds:\n",
        "  print(\"input shape: \", inputs.shape)\n",
        "  print(\"input dtype: \", inputs.dtype)\n",
        "  print(\"targets shape: \", targets.shape)\n",
        "  print(\"targets dtype: \", targets.dtype)\n",
        "  print('inputs[0]: ', inputs[0])\n",
        "  print('targets[0]: ', targets[0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEyeDCVK0-0p",
        "outputId": "86842351-be67-4020-918d-0a45a7463be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape:  (32,)\n",
            "input dtype:  <dtype: 'string'>\n",
            "targets shape:  (32,)\n",
            "targets dtype:  <dtype: 'int32'>\n",
            "inputs[0]:  tf.Tensor(b'The oddly-named Vera-Ellen was to movie dancing what Sonja Henie was to movie ice-skating: blonde, girlish, always delightful to watch, but not an especially good actress and usually lumbered with weak material. When I watch Vera-Ellen\\'s sexy apache dance with Gene Kelly in \\'Words and Music\\', I can\\'t help noticing that her blouse (yellow with narrow red horizontal stripes) seems to be made out of the South Vietnam flag. For some reason, the very American Vera-Ellen starred in *two* musicals (made several years apart) set in Edinburgh, a city not noted for its tap-dancers: \\'Let\\'s Be Happy\\' and \\'Happy Go Lovely\\'.<br /><br />In the latter, Cesar Romero plays an American impresario who for some reason is staging a musical in Edinburgh. There\\'s a vague attempt to link this show to the Edinburgh Festival, which is nonsense: the Festival is not a showcase for splashy leg-shows. We also see a couple of stock shots of the Royal Mile: apart from a few Highland accents, there\\'s absolutely no attempt to convey Scottish atmosphere in this movie. The funniest gag occurs at the very beginning, when we learn that the title of Romero\\'s show is \\'Frolics to You\\': this is a cheeky pun that Britons will get and Yanks won\\'t.<br /><br />Vera-Ellen is, as usual, cute and appealing and an impressive dancer, but the very few musical numbers in this movie are boring and bad. The plot -- mistaken identity between magnate David Niven and reporter Gordon Jackson -- is brainless, though no more so than the plots of several dozen Hollywood musicals. Romero is less annoying than usual here, probably because (for once) he isn\\'t required to convince us that he\\'s interested in bedding the heroine.<br /><br />The single biggest offence of this movie is its misuse of Bobby Howes. The father of Sally Ann Howes was a major star of West End stage musicals; his wistful rendition of \"She\\'s My Lovely\" was a big hit in Britain in 1937. Here, he shows up in several scenes as Romero\\'s dogsbody but never has a chance to participate in a musical number, nor even any real comedy. It\\'s absolutely criminal that this movie -- with a title containing the word \\'Lovely\\', sure to evoke Howes\\'s greatest hit -- would cast a major British musical star but give him nothing to do!<br /><br />The delightful character actress Ambrosine Phillpotts (whom I worked with once) shines in one restaurant sequence, and there\\'s a glimpse of the doomed beauty Kay Kendall. As Vera-Ellen\\'s confidante, somebody named Diane Hart speaks in one of the most annoying voices I\\'ve ever heard: it sounds like an attempt to imitate Joan Greenwood and Glynis Johns both at the same go, but doesn\\'t match either. Val Guest has a story credit, but this movie doesn\\'t come up to the quality of his brilliant comedies. The colour photography is wretched, though I realise that postwar Britain could not afford Hollywood\\'s process work. \\'Happy Go Lovely\\' is at utmost best a pleasant time-waster, with \\'waster\\' being the operative word. I\\'ll rate this movie just 4 out of 10.', shape=(), dtype=string)\n",
            "targets[0]:  tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset yields inputs that are tf.string tensors and targets that are int32 tensors encoding the value \"0\" or \"1\"\n",
        "\n",
        "\n",
        "All set, now let's try learnign something from this data\n"
      ],
      "metadata": {
        "id": "rkkTRznT2IO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddedLayer(keras.Layer):\n",
        "  def call(self, x):\n",
        "    return tf.one_hot(x, depth=max_length)\n",
        "\n",
        "inputs = keras.Input(shape=(None, ), dtype='int64')\n",
        "embedded = EmbeddedLayer()(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "6VVVXhop2EXP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "faac7730-da12-4910-94f6-14ece6dd21c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedded_layer_2 (\u001b[38;5;33mEmbeddedLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m162,048\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedded_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EmbeddedLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">162,048</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m162,113\u001b[0m (633.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,113</span> (633.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m162,113\u001b[0m (633.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,113</span> (633.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                      save_best_only=True)\n",
        "    ]\n",
        "\n",
        "history = model.fit(int_train_ds.cache(),\n",
        "  validation_data=int_val_ds.cache(),\n",
        "  epochs=10,\n",
        "  callbacks=callbacks)\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJrWeNRPrubQ",
        "outputId": "7d6c8cd8-0463-4568-892e-67868334ffd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.8756 - loss: 0.3127 - val_accuracy: 0.8324 - val_loss: 0.4087\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 39ms/step - accuracy: 0.8787 - loss: 0.3027 - val_accuracy: 0.8116 - val_loss: 0.4255\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.8802 - loss: 0.3024 - val_accuracy: 0.8284 - val_loss: 0.4361\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.8823 - loss: 0.2985 - val_accuracy: 0.8212 - val_loss: 0.4565\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.8858 - loss: 0.2904 - val_accuracy: 0.8112 - val_loss: 0.4510\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.8861 - loss: 0.2876 - val_accuracy: 0.7768 - val_loss: 0.5387\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.8854 - loss: 0.2859 - val_accuracy: 0.8218 - val_loss: 0.4900\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.8934 - loss: 0.2768 - val_accuracy: 0.8184 - val_loss: 0.4541\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.8919 - loss: 0.2767 - val_accuracy: 0.8236 - val_loss: 0.4676\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.8955 - loss: 0.2715 - val_accuracy: 0.8170 - val_loss: 0.5151\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8177 - loss: 0.5079\n",
            "Test acc: 0.817\n"
          ]
        }
      ]
    }
  ]
}