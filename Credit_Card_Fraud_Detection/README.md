Dataset: https://huggingface.co/datasets/dazzle-nu/CIS435-CreditCardFraudDetection

All the code I'll write in .py files instead of .ipynb because I lack practice/experience in working with classes and functions. So this project is something like training/learning new things, new tech, learning how to write clear, readable and maintainable code. All the functions are written in the src/data_preprocessing.py folder and executed in main.py. The data_preprocessing.ipynb is just for testing code/functions and then transferring them to the .py file.

When I am done with the standard ML as loading data, visualizing, preprocessing(which is very complex for this dataset that involves different types of data to deal with), training. I want to try different kinds of real world practices as:

Command line arguments (using argparse) - I am a little familiar with this concept, has to deal with it in other project(self driving car if my mind serves me)

Configuration files (YAML/JSON)

Logging instead of print statements

Error handling

Unit tests for functions

Docker containerization

Model versioning and experiment tracking (MLflow, Weights & Biases)

Building a simple REST API around the model (claude and gpt said FastAPI is great for this)

Deploy it locally, then to cloud platforms

Add monitoring and health checks
